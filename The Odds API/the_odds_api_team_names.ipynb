{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Team Names from the Odds API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching events for men's NCAA basketball\n",
      "Total unique NCAA basketball teams fetched: 195\n"
     ]
    }
   ],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Define sport keys for men's and women's NCAA basketball\n",
    "sport_keys = {\n",
    "    \"men\": \"basketball_ncaab\",\n",
    "}\n",
    "\n",
    "# Base URL for The Odds API\n",
    "base_url = \"https://api.the-odds-api.com/v4\"\n",
    "\n",
    "def fetch_events(sport_key, gender):\n",
    "    url = f\"{base_url}/sports/{sport_key}/events\"\n",
    "    params = {\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json(), gender\n",
    "    else:\n",
    "        print(f\"Error fetching events for {sport_key}: {response.status_code} - {response.text}\")\n",
    "        return [], gender\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    all_teams = []\n",
    "\n",
    "    for gender, sport_key in sport_keys.items():\n",
    "        print(f\"Fetching events for {gender}'s NCAA basketball\")\n",
    "        events, gender = fetch_events(sport_key, gender)\n",
    "        \n",
    "        for event in events:\n",
    "            home_team = event.get(\"home_team\")\n",
    "            away_team = event.get(\"away_team\")\n",
    "            if home_team:\n",
    "                all_teams.append({\"team\": home_team, \"gender\": gender})\n",
    "            if away_team:\n",
    "                all_teams.append({\"team\": away_team, \"gender\": gender})\n",
    "        \n",
    "        # Respect API rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Load existing team names if file exists\n",
    "    existing_teams = []\n",
    "    if os.path.exists('ncaa_basketball_teams.json'):\n",
    "        with open('ncaa_basketball_teams.json', 'r') as f:\n",
    "            existing_teams = json.load(f)\n",
    "\n",
    "    # Combine new and existing teams\n",
    "    all_teams.extend(existing_teams)\n",
    "\n",
    "    # Remove duplicates by creating a set of tuples (team, gender) and convert back to list of dicts\n",
    "    unique_teams = [dict(t) for t in set(tuple(team.items()) for team in all_teams)]\n",
    "\n",
    "    # Save the list of teams to a JSON file\n",
    "    with open('ncaa_basketball_teams.json', 'w') as f:\n",
    "        json.dump(unique_teams, f, indent=4)\n",
    "\n",
    "    print(f\"Total unique NCAA basketball teams fetched: {len(unique_teams)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match fetched names to my prediction database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Match Success Rate: 74.70%\n",
      "Matched teams saved to 'matched_teams_master.csv'\n",
      "Unmatched teams with top suggestions saved to 'unmatched_teams_with_suggestions.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Load unique teams and prediction dataset\n",
    "with open('ncaa_basketball_teams.json', 'r') as f:\n",
    "    unique_teams = json.load(f)\n",
    "\n",
    "prediction_teams = pd.read_parquet(\"/Users/zacharias/Dropbox/Python/Project Jupiter/Project Zoccer/ncaa_basketball/project_ncaa_live/ncaa_team_scores_working_file.parquet\").columns\n",
    "\n",
    "# Function to normalize team names by removing punctuation and converting to lowercase\n",
    "def normalize_name(name):\n",
    "    return re.sub(r\"[^a-zA-Z0-9 ]\", \"\", name).lower().replace(\" \", \"_\")\n",
    "\n",
    "# Function to create name variations by removing the last one or two words\n",
    "def create_name_variations(name):\n",
    "    words = name.split()\n",
    "    variations = [name]  # Original name\n",
    "    if len(words) > 1:\n",
    "        variations.append(\" \".join(words[:-1]))  # Drop last word\n",
    "    if len(words) > 2:\n",
    "        variations.append(\" \".join(words[:-2]))  # Drop last two words\n",
    "    return variations\n",
    "\n",
    "# Load existing matched teams to avoid adding them to unmatched\n",
    "master_file = \"matched_teams_master.csv\"\n",
    "if os.path.exists(master_file):\n",
    "    master_df = pd.read_csv(master_file)\n",
    "    already_matched_teams = set(master_df[\"original_name\"].values)\n",
    "else:\n",
    "    master_df = pd.DataFrame(columns=[\"original_name\", \"expected_name\", \"best_match\", \"match_score\"])\n",
    "    already_matched_teams = set()\n",
    "\n",
    "# Lists to store new matched and unmatched teams\n",
    "matched_teams = []\n",
    "unmatched_teams = []\n",
    "\n",
    "# Try to match each team in unique_teams to prediction_teams\n",
    "for team_entry in unique_teams:\n",
    "    original_name = team_entry['team']\n",
    "\n",
    "    # Skip if already matched\n",
    "    if original_name in already_matched_teams:\n",
    "        continue\n",
    "\n",
    "    normalized_variations = [normalize_name(var) for var in create_name_variations(original_name)]\n",
    "    gender_suffix = \"_M\" if team_entry['gender'] == 'men' else \"_F\"\n",
    "\n",
    "    # Collect all matches across all variations\n",
    "    all_matches = []\n",
    "    for name_variation in normalized_variations:\n",
    "        full_team_name = f\"{name_variation}{gender_suffix}\"\n",
    "        matches_for_variation = process.extract(full_team_name, prediction_teams, limit=5, scorer=fuzz.token_sort_ratio)\n",
    "        all_matches.extend(matches_for_variation)\n",
    "\n",
    "    # Sort and deduplicate all matches by score and select the top 5 unique matches\n",
    "    all_matches = sorted(set(all_matches), key=lambda x: x[1], reverse=True)[:5]\n",
    "    unique_matches = all_matches\n",
    "\n",
    "    # Check if the best match is above the threshold\n",
    "    if unique_matches and unique_matches[0][1] >= 85:\n",
    "        matched_teams.append({\n",
    "            \"original_name\": original_name,\n",
    "            \"expected_name\": f\"{normalize_name(original_name)}{gender_suffix}\",\n",
    "            \"best_match\": unique_matches[0][0],\n",
    "            \"match_score\": unique_matches[0][1]\n",
    "        })\n",
    "    else:\n",
    "        # If no good match is found, save the original name with the top 5 unique matches for manual review\n",
    "        unmatched_teams.append({\n",
    "            \"original_name\": original_name,\n",
    "            \"expected_name\": f\"{normalize_name(original_name)}{gender_suffix}\",\n",
    "            \"top_matches\": unique_matches  # List of top 5 unique matches and scores\n",
    "        })\n",
    "\n",
    "# Append new matches to the master file without overwriting existing entries\n",
    "new_matches_df = pd.DataFrame(matched_teams)\n",
    "master_df = pd.concat([master_df, new_matches_df], ignore_index=True).drop_duplicates(subset=\"original_name\")\n",
    "master_df.to_csv(master_file, index=False)\n",
    "\n",
    "# Save unmatched teams with suggestions for manual review\n",
    "with open(\"unmatched_teams_with_suggestions.json\", \"w\") as f:\n",
    "    json.dump(unmatched_teams, f, indent=4)\n",
    "\n",
    "# Calculate success rate based on newly processed teams\n",
    "newly_matched_count = len(matched_teams)\n",
    "unmatched_count = len(unmatched_teams)\n",
    "\n",
    "# Calculate success rate\n",
    "if newly_matched_count + unmatched_count > 0:\n",
    "    match_success_rate = (newly_matched_count / (newly_matched_count + unmatched_count)) * 100\n",
    "else:\n",
    "    match_success_rate = 100  # If no teams processed, assume full success\n",
    "\n",
    "print(f\"\\nMatch Success Rate: {match_success_rate:.2f}%\")\n",
    "\n",
    "print(\"Matched teams saved to 'matched_teams_master.csv'\")\n",
    "print(\"Unmatched teams with top suggestions saved to 'unmatched_teams_with_suggestions.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zachariasenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
